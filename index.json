[{"authors":["ruiming"],"categories":null,"content":"I am a Ph.D. student in Bioengineering at UC Berkeley. I work on computational imaging and microscopy advised by Prof. Laura Waller.\nBefore coming to Berkeley, I spent six years at UCLA and obtained B.S. in Computer Science and Applied Mathematics with Cum Laude and M.S. in Computer Science. My past research was on computer vision and medical imaging. During M.S., I worked on MRI imaging analysis advised by Prof. Kyung Hyun Sung and Prof. Fabien Scalzo. In my undergrad, I worked on knowledge graph parsing/explainable AI advised by Prof. Song-Chun Zhu.\nBesides research, I spend time on downhill skiing, running, trekking, photography. And my name is pronounced as \u0026ldquo;Rei-Ming Tsao/Chao\u0026rdquo; :)\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"c7271ebcef3e1181bf08b35e3dcc6a4c","permalink":"https://rmcao.github.io/authors/ruiming/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/ruiming/","section":"authors","summary":"I am a Ph.D. student in Bioengineering at UC Berkeley. I work on computational imaging and microscopy advised by Prof. Laura Waller.\nBefore coming to Berkeley, I spent six years at UCLA and obtained B.","tags":null,"title":"Ruiming Cao","type":"authors"},{"authors":["Ruiming Cao","Michael Kellman","David Ren","Laura Waller"],"categories":[],"content":"","date":1593199777,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593199777,"objectID":"c818855ff79eea9c19f72142f63a7ed1","permalink":"https://rmcao.github.io/project/motion3ddpc/","publishdate":"2020-06-26T12:29:37-07:00","relpermalink":"/project/motion3ddpc/","section":"project","summary":"We developed a rapid, stage-free phase tomography by hand spinning the defocus knob while updating illumination patterns and taking measurements at a high frame rate, and the defocus trajectory can be inferred with the algorithm.","tags":["CI"],"title":"Algorithmic self-calibration for 3D differential phase contrast microscopy","type":"project"},{"authors":["Ruiming Cao","Xinran Zhong","Sohrab Afshari","Ely Felker","Voraparee Suvannarerg","Teeravut Tubtawee","Sitaram Vangala","Fabien Scalzo","Steven Raman","Kyunghyun Sung"],"categories":[],"content":"","date":1582233155,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582233155,"objectID":"e11deed2fe2381b5b5723f3dfa344aa2","permalink":"https://rmcao.github.io/project/radaicomparison/","publishdate":"2020-02-20T14:12:35-07:00","relpermalink":"/project/radaicomparison/","section":"project","summary":"We validated our previously developed algorithm for prostate cancer detection using an independent patient cohort who went through radical prostatectomy and compared with genitourinary radiologists under the same setting.","tags":["BI"],"title":"GU Radiologists vs AI in Detection of Prostate Cancer on MRI","type":"project"},{"authors":["Ruiming Cao","Amir Bajgiran","Sohrab Afshari","Sepideh Shakeri","Xinran Zhong","Dieter Enzmann","Steven Raman","Kyunghyun Sung"],"categories":[],"content":"Multi-parametric MRI (mp-MRI) is considered the best non-invasive imaging modality for diagnosing prostate cancer (PCa). However, mp-MRI for PCa diagnosis is currently limited by the qualitative or semi-quantitative interpretation criteria, leading to inter-reader variability and a suboptimal ability to assess lesion aggressiveness. Convolutional neural networks (CNNs) are a powerful method to automatically learn the discriminative features for various tasks, including cancer detection. We propose a novel multi-class CNN, FocalNet, to jointly detect PCa lesions and predict their aggressiveness using Gleason score (GS). FocalNet characterizes lesion aggressiveness and fully utilizes distinctive knowledge from mp-MRI. We collected a prostate mp-MRI dataset from 417 patients who underwent 3T mp-MRI exams prior to robotic-assisted laparoscopic prostatectomy (RALP). FocalNet is trained and evaluated in this large study cohort with 5-fold cross-validation. In the free-response receiver operating characteristics (FROC) analysis for lesion detection, FocalNet achieved 89.7% and 87.9% sensitivity for index lesions and clinically significant lesions at 1 false positive per patient, respectively. For GS classification, evaluated by the receiver operating characteristics (ROC) analysis, FocalNet received the area under the curve (AUC) of 0.81 and 0.79 for the classifications of clinically significant PCa (GS\u0026gt;=3+4) and PCa with GS\u0026gt;=4+3, respectively. With the comparison to the prospective performance of radiologists using the current diagnostic guideline, FocalNet demonstrated comparable detection sensitivity for index lesions and clinically significant lesions, only 3.4% and 1.5% lower than highly experienced radiologists without statistical significance.\n","date":1551293613,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551293613,"objectID":"3afbfa784af4969164d1c461c8f43f0e","permalink":"https://rmcao.github.io/project/focalnet/","publishdate":"2019-02-27T11:53:33-07:00","relpermalink":"/project/focalnet/","section":"project","summary":"We proposed a multi-class CNN to jointly detect prostate cancer lesions and characterizes their histopathological aggressiveness by fully utilizing distinctive knowledge from multi-parametric MRI.","tags":["BI"],"title":"Joint Prostate Cancer Detection and Histological Score Prediction on MRI","type":"project"},{"authors":["Quanshi Zhang","Ruiming Cao","Feng Shi","Ying Nian Wu","Song-Chun Zhu"],"categories":[],"content":"","date":1529520888,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1529520888,"objectID":"d5545455cab64090b85cd28857c27e3e","permalink":"https://rmcao.github.io/project/explanatorygraph/","publishdate":"2018-06-20T11:54:48-07:00","relpermalink":"/project/explanatorygraph/","section":"project","summary":"We proposed to automatically discover object parts in an unsupervised manner, which disentangles feature components of object parts from feature representations of each convolutional filter.","tags":["CV"],"title":"Interpreting CNN Knowledge via an Explanatory Graph","type":"project"},{"authors":["Quanshi Zhang","Ruiming Cao","Ying Nian Wu","Song-Chun Zhu"],"categories":[],"content":"Given a convolutional neural network (CNN) that is pre-trained for object classification, this paper proposes to use active question-answering to semanticize neural patterns in conv-layers of the CNN and mine part concepts. For each part concept, we mine neural patterns in the pre-trained CNN, which are related to the target part, and use these patterns to construct an And-Or graph (AOG) to represent a four-layer semantic hierarchy of the part. As an interpretable model, the AOG associates different CNN units with different explicit object parts. We use an active human-computer communication to incrementally grow such an AOG on the pre-trained CNN as follows. We allow the computer to actively identify objects, whose neural patterns cannot be explained by the current AOG. Then, the computer asks human about the unexplained objects, and uses the answers to automatically discover certain CNN patterns corresponding to the missing knowledge. We incrementally grow the AOG to encode new knowledge discovered during the active-learning process. In experiments, our method exhibits high learning efficiency. Our method uses about 1/6-1/3 of the part annotations for training, but achieves similar or better part-localization performance than fast-RCNN methods.\n","date":1513798676,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1513798676,"objectID":"4e8068f1c3e69caf1afcb90e046c5e02","permalink":"https://rmcao.github.io/project/growingpartgraph/","publishdate":"2017-12-20T12:37:56-07:00","relpermalink":"/project/growingpartgraph/","section":"project","summary":"We used active question-answering to weakly-supervised semanticize neural patterns in conv-layers of the CNN and mine part concepts.","tags":["CV"],"title":"Mining Object Parts from CNNs via Active Question-Answering","type":"project"}]